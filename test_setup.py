"""
Phase 1 Verification: LCEL Hello World (Gemini 2.5 Flash - Free Tier)
Tests: API connectivity, runnable chains, streaming
"""
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# Load environment variables
load_dotenv()

# Verify API key loaded
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("‚ùå GOOGLE_API_KEY not found in .env file!")

print(f"‚úÖ API Key loaded: {api_key[:10]}...{api_key[-4:]}\n")

# Step 1: Initialize Gemini 2.5 Flash (Free Tier Available)
llm = ChatGoogleGenerativeAI(
    model="models/gemini-2.5-flash",  # ‚úÖ Flash has generous free tier
    temperature=0,  # Deterministic for testing
    max_tokens=256,
)

print(f"‚úÖ Using model: models/gemini-2.5-flash")
print(f"   (Fast, efficient, and generous free tier limits)\n")

# Step 2: Create a prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Respond concisely."),
    ("human", "{question}")
])

# Step 3: Build LCEL chain using pipe operator
chain = prompt | llm | StrOutputParser()

# Step 4: Test synchronous invocation
if __name__ == "__main__":
    print("üß™ Testing LCEL Chain...\n")
    
    try:
        response = chain.invoke({"question": "What is LangChain in one sentence?"})
        print(f"‚úÖ Response: {response}\n")
        
        # Test streaming (critical for UX in later phases)
        print("üåä Testing Streaming...\n")
        print("Output: ", end="")
        for chunk in chain.stream({"question": "Count from 1 to 5, separated by commas"}):
            print(chunk, end="", flush=True)
        
        print("\n\n" + "="*60)
        print("‚úÖ Phase 1 Complete: Environment verified!")
        print("="*60)
        print("‚úÖ Model: Gemini 2.5 Flash (Free Tier)")
        print("‚úÖ LCEL chains working correctly")
        print("‚úÖ Streaming working correctly")
        print("‚úÖ Gemini API connected successfully")
        print("‚úÖ Ready for Phase 2: LLM Fundamentals")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå Error occurred: {type(e).__name__}")
        print(f"   Message: {str(e)}")
        print("\nüîç Troubleshooting:")
        print("   1. Verify API key in .env file")
        print("   2. Check internet connection")
        print("   3. Confirm Gemini API is enabled in Google AI Studio")
        raise